dialect = https://cdn.jsdelivr.net/gh/angelonuffer/dialect@d37c62e/code/0

// --- Independent Rules (No whitespace dependency) ---

// Comment syntax support (using negation grammar type)
newline_chars = {
  type: "alternative"
  options: [
    { type: "symbol" text: "
" }
    { type: "symbol" text: "\r" }
  ]
}

single_line_comment_char = {
  type: "negation"
  grammar: newline_chars
}

single_line_comment_content = {
  type: "repetition"
  grammar: single_line_comment_char
  format: "text"
  minimum: 0
}

single_line_comment = {
  type: "sequence"
  parts: [
    { type: "symbol" text: "/" }
    { type: "symbol" text: "/" }
    single_line_comment_content
  ]
  format: "text"
}

asterisk_symbol = { type: "symbol" text: "*" }
slash_symbol = { type: "symbol" text: "/" }

not_asterisk = {
  type: "negation"
  grammar: asterisk_symbol
}

not_slash = {
  type: "negation"
  grammar: slash_symbol
}

asterisk_not_slash = {
  type: "sequence"
  parts: [
    asterisk_symbol
    not_slash
  ]
  format: "text"
}

multi_line_comment_content_char = {
  type: "alternative"
  options: [
    not_asterisk
    asterisk_not_slash
  ]
}

multi_line_comment_content = {
  type: "repetition"
  grammar: multi_line_comment_content_char
  format: "text"
  minimum: 0
}

multi_line_comment = {
  type: "sequence"
  parts: [
    slash_symbol
    asterisk_symbol
    multi_line_comment_content
    asterisk_symbol
    slash_symbol
  ]
  format: "text"
}

comment = {
  type: "alternative"
  options: [
    single_line_comment
    multi_line_comment
  ]
}

// Basic identifier parts (shared)
identifier_start = {
  type: "alternative"
  options: [
    { type: "range" from: "a" to: "z" }
    { type: "range" from: "A" to: "Z" }
    { type: "symbol" text: "_" }
  ]
}

identifier_char = {
  type: "alternative"
  options: [
    { type: "range" from: "a" to: "z" }
    { type: "range" from: "A" to: "Z" }
    { type: "range" from: "0" to: "9" }
    { type: "symbol" text: "_" }
  ]
}

hex_digit = {
  type: "alternative"
  options: [
    { type: "range" from: "0" to: "9" }
    { type: "range" from: "a" to: "f" }
    { type: "range" from: "A" to: "F" }
  ]
}

// Primitive content rules (no whitespace)
string_content_char = {
  type: "alternative"
  options: [
    {
      type: "sequence"
      parts: [
        { type: "symbol" text: "\\" }
        {
          type: "alternative"
          options: [
            { type: "symbol" text: "'" }
            { type: "symbol" text: "\\" }
            { type: "symbol" text: "n" }
            { type: "symbol" text: "r" }
            { type: "symbol" text: "t" }
            { type: "symbol" text: "b" }
            { type: "symbol" text: "f" }
            {
              type: "sequence"
              parts: [
                { type: "symbol" text: "u" }
                { type: "repetition" grammar: hex_digit minimum: 4 maximum: 4 format: "text" }
              ]
              format: "text"
            }
          ]
        }
      ]
      format: "text"
    }
    { type: "range" from: " " to: "&" }
    { type: "range" from: "(" to: "[" }
    { type: "range" from: "]" to: "~" }
  ]
}

char_class_item = {
  type: "alternative"
  options: [
    {
      type: "sequence"
      parts: [
        { name: "backslash" grammar: { type: "symbol" text: "\\" } }
        { name: "char" grammar: { type: "range" from: " " to: "~" } }
      ]
      format: "object"
    }
    {
      type: "sequence"
      parts: [
        {
          name: "from"
          grammar: {
            type: "alternative"
            options: [
              { type: "range" from: " " to: "\\" }
              { type: "range" from: "^" to: "~" }
            ]
          }
        }
        { name: "dash" grammar: { type: "symbol" text: "-" } }
        {
          name: "to"
          grammar: {
            type: "alternative"
            options: [
              { type: "range" from: " " to: "\\" }
              { type: "range" from: "^" to: "~" }
            ]
          }
        }
      ]
      format: "object"
    }
    {
      type: "sequence"
      parts: [
        {
          name: "char"
          grammar: {
            type: "alternative"
            options: [
              { type: "range" from: " " to: "\\" }
              { type: "range" from: "^" to: "~" }
            ]
          }
        }
      ]
      format: "object"
    }
  ]
}

// --- Whitespace-Dependent Rules Factory ---

make_antlr_grammar = { ws_char } => (
  ws = {
    type: "repetition"
    grammar: ws_char
    format: "text"
    minimum: 1
  }

  opt_ws = {
    type: "repetition"
    grammar: ws_char
    format: "text"
    minimum: 0
  }

  // Identifiers (defined here to ensure any future whitespace dependency is handled)
  identifier = {
    type: "sequence"
    parts: [
      identifier_start
      {
        type: "repetition"
        grammar: identifier_char
        format: "text"
        minimum: 0
      }
    ]
    format: "text"
  }

  parser_rule_name = {
    type: "sequence"
    parts: [
      { type: "range" from: "a" to: "z" }
      {
        type: "repetition"
        grammar: identifier_char
        format: "text"
        minimum: 0
      }
    ]
    format: "text"
  }

  lexer_rule_name = {
    type: "sequence"
    parts: [
      { type: "range" from: "A" to: "Z" }
      {
        type: "repetition"
        grammar: identifier_char
        format: "text"
        minimum: 0
      }
    ]
    format: "text"
  }

  string_literal = {
    type: "sequence"
    parts: [
      { name: "open" grammar: { type: "symbol" text: "'" } }
      { name: "content" grammar: {
        type: "repetition"
        grammar: string_content_char
        format: "text"
        minimum: 0
      }}
      { name: "close" grammar: { type: "symbol" text: "'" } }
    ]
    format: "object"
  }

  char_class = {
    type: "sequence"
    parts: [
      { name: "open" grammar: { type: "symbol" text: "[" } }
      { name: "content" grammar: {
        type: "repetition"
        grammar: char_class_item
        format: "list"
        minimum: 1
      }}
      { name: "close" grammar: { type: "symbol" text: "]" } }
    ]
    format: "object"
  }

  digits = {
    type: "repetition"
    grammar: { type: "range" from: "0" to: "9" }
    format: "text"
    minimum: 1
  }

  bounded_quantifier = {
    type: "sequence"
    parts: [
      { type: "symbol" text: "{" }
      digits
      {
        type: "repetition"
        grammar: {
          type: "sequence"
          parts: [
            { type: "symbol" text: "," }
            {
              type: "repetition"
              grammar: digits
              minimum: 0
              maximum: 1
              format: "text"
            }
          ]
          format: "text"
        }
        minimum: 0
        maximum: 1
        format: "text"
      }
      { type: "symbol" text: "}" }
    ]
    format: "text"
  }

  quantifier = {
    type: "alternative"
    options: [
      { type: "symbol" text: "*?" }
      { type: "symbol" text: "+?" }
      { type: "symbol" text: "*" }
      { type: "symbol" text: "+" }
      { type: "symbol" text: "?" }
      bounded_quantifier
    ]
  }

  lexer_command = {
    type: "sequence"
    parts: [
      { name: "name" grammar: identifier }
      { name: "args" grammar: {
        type: "repetition"
        grammar: {
          type: "sequence"
          parts: [
            { name: "open" grammar: { type: "symbol" text: "(" } }
            { name: "ws1" grammar: opt_ws }
            { name: "arg" grammar: identifier }
            { name: "ws2" grammar: opt_ws }
            { name: "close" grammar: { type: "symbol" text: ")" } }
          ]
          format: "object"
        }
        minimum: 0
        maximum: 1
        format: "list"
      }}
    ]
    format: "object"
  }

  // --- Level 0 Grammar (No nested groups) ---

  rule_element_0 = {
    type: "alternative"
    options: [
      string_literal
      char_class
      { type: "symbol" text: "." }
      identifier
    ]
  }

  element_with_quantifier_0 = {
    type: "sequence"
    parts: [
      { name: "element" grammar: rule_element_0 }
      { name: "quantifier" grammar: {
        type: "repetition"
        grammar: quantifier
        minimum: 0
        maximum: 1
        format: "text"
      }}
    ]
    format: "object"
  }

  rule_alt_0 = {
    type: "sequence"
    parts: [
      { name: "first" grammar: element_with_quantifier_0 }
      { name: "rest" grammar: {
        type: "repetition"
        grammar: {
          type: "sequence"
          parts: [
            { name: "ws" grammar: ws }
            { name: "element" grammar: element_with_quantifier_0 }
          ]
          format: "object"
        }
        format: "list"
        minimum: 0
      }}
    ]
    format: "object"
  }

  rule_body_0 = {
    type: "sequence"
    parts: [
      { name: "first" grammar: rule_alt_0 }
      { name: "rest" grammar: {
        type: "repetition"
        grammar: {
          type: "sequence"
          parts: [
            { name: "ws1" grammar: opt_ws }
            { name: "pipe" grammar: { type: "symbol" text: "|" } }
            { name: "ws2" grammar: opt_ws }
            { name: "alt" grammar: rule_alt_0 }
          ]
          format: "object"
        }
        format: "list"
        minimum: 0
      }}
    ]
    format: "object"
  }

  // --- Level 1 Grammar (One level of nested groups) ---

  group_1 = {
    type: "sequence"
    parts: [
      { name: "open" grammar: { type: "symbol" text: "(" } }
      { name: "ws1" grammar: opt_ws }
      { name: "body" grammar: rule_body_0 }
      { name: "ws2" grammar: opt_ws }
      { name: "close" grammar: { type: "symbol" text: ")" } }
    ]
    format: "object"
  }

  rule_element_1 = {
    type: "alternative"
    options: [
      string_literal
      char_class
      { type: "symbol" text: "." }
      group_1
      identifier
    ]
  }

  element_with_quantifier_1 = {
    type: "sequence"
    parts: [
      { name: "element" grammar: rule_element_1 }
      { name: "quantifier" grammar: {
        type: "repetition"
        grammar: quantifier
        minimum: 0
        maximum: 1
        format: "text"
      }}
    ]
    format: "object"
  }

  rule_alt_1 = {
    type: "sequence"
    parts: [
      { name: "first" grammar: element_with_quantifier_1 }
      { name: "rest" grammar: {
        type: "repetition"
        grammar: {
          type: "sequence"
          parts: [
            { name: "ws" grammar: ws }
            { name: "element" grammar: element_with_quantifier_1 }
          ]
          format: "object"
        }
        format: "list"
        minimum: 0
      }}
    ]
    format: "object"
  }

  rule_body_1 = {
    type: "sequence"
    parts: [
      { name: "first" grammar: rule_alt_1 }
      { name: "rest" grammar: {
        type: "repetition"
        grammar: {
          type: "sequence"
          parts: [
            { name: "ws1" grammar: opt_ws }
            { name: "pipe" grammar: { type: "symbol" text: "|" } }
            { name: "ws2" grammar: opt_ws }
            { name: "alt" grammar: rule_alt_1 }
          ]
          format: "object"
        }
        format: "list"
        minimum: 0
      }}
    ]
    format: "object"
  }

  // --- Level 2 Grammar (Two levels of nested groups) ---

  group_2 = {
    type: "sequence"
    parts: [
      { name: "open" grammar: { type: "symbol" text: "(" } }
      { name: "ws1" grammar: opt_ws }
      { name: "body" grammar: rule_body_1 }
      { name: "ws2" grammar: opt_ws }
      { name: "close" grammar: { type: "symbol" text: ")" } }
    ]
    format: "object"
  }

  rule_element_2 = {
    type: "alternative"
    options: [
      string_literal
      char_class
      { type: "symbol" text: "." }
      group_2
      identifier
    ]
  }

  element_with_quantifier_2 = {
    type: "sequence"
    parts: [
      { name: "element" grammar: rule_element_2 }
      { name: "quantifier" grammar: {
        type: "repetition"
        grammar: quantifier
        minimum: 0
        maximum: 1
        format: "text"
      }}
    ]
    format: "object"
  }

  rule_alt_2 = {
    type: "sequence"
    parts: [
      { name: "first" grammar: element_with_quantifier_2 }
      { name: "rest" grammar: {
        type: "repetition"
        grammar: {
          type: "sequence"
          parts: [
            { name: "ws" grammar: ws }
            { name: "element" grammar: element_with_quantifier_2 }
          ]
          format: "object"
        }
        format: "list"
        minimum: 0
      }}
    ]
    format: "object"
  }

  rule_body_2 = {
    type: "sequence"
    parts: [
      { name: "first" grammar: rule_alt_2 }
      { name: "rest" grammar: {
        type: "repetition"
        grammar: {
          type: "sequence"
          parts: [
            { name: "ws1" grammar: opt_ws }
            { name: "pipe" grammar: { type: "symbol" text: "|" } }
            { name: "ws2" grammar: opt_ws }
            { name: "alt" grammar: rule_alt_2 }
          ]
          format: "object"
        }
        format: "list"
        minimum: 0
      }}
    ]
    format: "object"
  }

  // Use the deepest level for actual grammar
  rule_element = rule_element_2
  rule_body = rule_body_2

  // Parser rule definition
  parser_rule = {
    type: "sequence"
    parts: [
      { name: "name" grammar: parser_rule_name }
      { name: "ws1" grammar: opt_ws }
      { name: "colon" grammar: { type: "symbol" text: ":" } }
      { name: "ws2" grammar: opt_ws }
      { name: "body" grammar: rule_body }
      { name: "ws3" grammar: opt_ws }
      { name: "semicolon" grammar: { type: "symbol" text: ";" } }
    ]
    format: "object"
  }

  // Lexer rule definition
  lexer_rule = {
    type: "sequence"
    parts: [
      { name: "fragment" grammar: {
        type: "repetition"
        grammar: {
          type: "sequence"
          parts: [
            { name: "keyword" grammar: { type: "symbol" text: "fragment" } }
            { name: "ws" grammar: ws }
          ]
          format: "object"
        }
        minimum: 0
        maximum: 1
        format: "list"
      }}
      { name: "name" grammar: lexer_rule_name }
      { name: "ws1" grammar: opt_ws }
      { name: "colon" grammar: { type: "symbol" text: ":" } }
      { name: "ws2" grammar: opt_ws }
      { name: "body" grammar: rule_body }
      { name: "ws_command" grammar: opt_ws }
      { name: "commands" grammar: {
        type: "repetition"
        grammar: {
          type: "sequence"
          parts: [
            { name: "arrow" grammar: { type: "symbol" text: "->" } }
            { name: "ws1" grammar: opt_ws }
            { name: "first" grammar: lexer_command }
            { name: "rest" grammar: {
              type: "repetition"
              grammar: {
                type: "sequence"
                parts: [
                  { name: "ws_pre" grammar: opt_ws }
                  { name: "comma" grammar: { type: "symbol" text: "," } }
                  { name: "ws_post" grammar: opt_ws }
                  { name: "command" grammar: lexer_command }
                ]
                format: "object"
              }
              format: "list"
              minimum: 0
            }}
          ]
          format: "object"
        }
        minimum: 0
        maximum: 1
        format: "list"
      }}
      { name: "ws3" grammar: opt_ws }
      { name: "semicolon" grammar: { type: "symbol" text: ";" } }
    ]
    format: "object"
  }

  mode_decl = {
    type: "sequence"
    parts: [
      { name: "keyword" grammar: { type: "symbol" text: "mode" } }
      { name: "ws1" grammar: ws }
      { name: "name" grammar: identifier }
      { name: "ws2" grammar: opt_ws }
      { name: "semicolon" grammar: { type: "symbol" text: ";" } }
    ]
    format: "object"
  }

  // Any rule (parser or lexer) or top-level declaration - try lexer first
  any_rule = {
    type: "alternative"
    options: [
      lexer_rule
      parser_rule
      mode_decl
    ]
  }

  // Grammar declaration
  grammar_decl = {
    type: "sequence"
    parts: [
      { name: "kind" grammar: {
        type: "repetition"
        grammar: {
          type: "alternative"
          options: [
            { type: "symbol" text: "lexer" }
            { type: "symbol" text: "parser" }
          ]
        }
        minimum: 0
        maximum: 1
        format: "text"
      }}
      { name: "ws_kind" grammar: opt_ws }
      { name: "keyword" grammar: { type: "symbol" text: "grammar" } }
      { name: "ws1" grammar: ws }
      { name: "name" grammar: identifier }
      { name: "ws2" grammar: opt_ws }
      { name: "semicolon" grammar: { type: "symbol" text: ";" } }
    ]
    format: "object"
  }

  // Full grammar with optional rules
  antlr_grammar = {
    type: "sequence"
    parts: [
      { name: "ws_start" grammar: opt_ws }
      { name: "grammar_decl" grammar: grammar_decl }
      { name: "rules" grammar: {
        type: "repetition"
        grammar: {
          type: "sequence"
          parts: [
            { name: "ws" grammar: opt_ws }
            { name: "rule" grammar: any_rule }
          ]
          format: "object"
        }
        format: "list"
        minimum: 0
      }}
      { name: "ws_end" grammar: opt_ws }
    ]
    format: "object"
  }

  antlr_grammar
)

// --- Grammar Instances ---

ws_char_base = {
  type: "alternative"
  options: [
    { type: "symbol" text: " " }
    { type: "symbol" text: "\t" }
    { type: "symbol" text: "
" }
    { type: "symbol" text: "\r" }
  ]
}

ws_char_parse = {
  type: "alternative"
  options: [
    { type: "symbol" text: " " }
    { type: "symbol" text: "\t" }
    { type: "symbol" text: "
" }
    { type: "symbol" text: "\r" }
    comment
  ]
}

ws_char_generate = ws_char_base

antlr_grammar_parse = make_antlr_grammar({ ws_char: ws_char_parse })
antlr_grammar_generate = make_antlr_grammar({ ws_char: ws_char_generate })

// --- to_dialect ---

to_dialect_char_class_item = item =>
  | (item.dash == "-") = { type: "range" from: item.from to: item.to }
  | (item.backslash == "\\") = { type: "symbol" text: item.char }
  | { type: "symbol" text: item.char }

to_dialect_char_class = { items index result } =>
  | (index >= items[.]) = { type: "alternative" options: result }
  | to_dialect_char_class({
      items: items
      index: index + 1
      result: [ ...result to_dialect_char_class_item(items[index]) ]
    })

to_dialect_quantifier = { grammar quantifier } =>
  | (quantifier == "*") = { type: "repetition" grammar: grammar minimum: 0 }
  | (quantifier == "+") = { type: "repetition" grammar: grammar minimum: 1 }
  | (quantifier == "?") = { type: "repetition" grammar: grammar minimum: 0 maximum: 1 }
  | (quantifier == "*?") = { type: "repetition" grammar: grammar minimum: 0 }
  | (quantifier == "+?") = { type: "repetition" grammar: grammar minimum: 1 }
  | (quantifier == "") = grammar
  | { type: "repetition" grammar: grammar }

to_dialect_is_string = val => (val == val + "")

to_dialect_element = { element convert_body } =>
  | (to_dialect_is_string(element) & element == ".") = { type: "negation" grammar: { type: "symbol" text: "" } }
  | (to_dialect_is_string(element)) = { type: "reference" name: element }
  | (element.open == "(") = convert_body(element.body)
  | (element.open == "'") = { type: "symbol" text: element.content }
  | (element.open == "[") = to_dialect_char_class({ items: element.content index: 0 result: [] })
  | { type: "reference" name: "unknown" }

to_dialect_collect_elements = { first rest convert_body index result } =>
  | (index > rest[.]) = result
  | (index == 0) = to_dialect_collect_elements({
      first: first
      rest: rest
      convert_body: convert_body
      index: 1
      result: [ to_dialect_quantifier({
        grammar: to_dialect_element({ element: first.element convert_body: convert_body })
        quantifier: first.quantifier
      }) ]
    })
  | to_dialect_collect_elements({
      first: first
      rest: rest
      convert_body: convert_body
      index: index + 1
      result: [
        ...result
        to_dialect_quantifier({
          grammar: to_dialect_element({ element: rest[index - 1].element.element convert_body: convert_body })
          quantifier: rest[index - 1].element.quantifier
        })
      ]
    })

to_dialect_alt = { alt convert_body } =>
  | (alt.rest[.] == 0) = to_dialect_quantifier({
      grammar: to_dialect_element({ element: alt.first.element convert_body: convert_body })
      quantifier: alt.first.quantifier
    })
  | {
      type: "sequence"
      parts: to_dialect_collect_elements({
        first: alt.first
        rest: alt.rest
        convert_body: convert_body
        index: 0
        result: []
      })
    }

to_dialect_collect_alts = { first rest index result } =>
  | (index > rest[.]) = result
  | (index == 0) = to_dialect_collect_alts({
      first: first
      rest: rest
      index: 1
      result: [ to_dialect_alt({ alt: first convert_body: to_dialect_body }) ]
    })
  | to_dialect_collect_alts({
      first: first
      rest: rest
      index: index + 1
      result: [
        ...result
        to_dialect_alt({ alt: rest[index - 1].alt convert_body: to_dialect_body })
      ]
    })

to_dialect_body = body =>
  | (body.rest[.] == 0) = to_dialect_alt({ alt: body.first convert_body: to_dialect_body })
  | {
      type: "alternative"
      options: to_dialect_collect_alts({
        first: body.first
        rest: body.rest
        index: 0
        result: []
      })
    }

to_dialect_rules = { rules index result } =>
  | (index >= rules[.]) = result
  | (rules[index].rule.body == 0) = to_dialect_rules({ rules: rules index: index + 1 result: result })
  | to_dialect_rules({
      rules: rules
      index: index + 1
      result: {
        ...result
        [rules[index].rule.name]: to_dialect_body(rules[index].rule.body)
      }
    })

ast_to_dialect = { ast } => to_dialect_rules({ rules: ast.rules index: 0 result: {} })

// --- API ---

// Parse function
parse = { input } => dialect.parse({
  input: input
  grammar: antlr_grammar_parse
})

// Generate function
generate = { ast } => dialect.generate({
  value: ast
  grammar: antlr_grammar_generate
})

// Export API
{
  parse: parse
  generate: generate
  to_dialect: ast_to_dialect
  grammar: antlr_grammar_parse
}
